{
 "metadata": {
  "name": "",
  "signature": "sha256:fd7b0db886eac82774084bdf5f09ed912a0bba8d6152caf6d2181d3e14c0a4c2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Importing and Formating Our Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import graphlab as gl\n",
      "import networkx as nx\n",
      "\n",
      "baseline_path = \"/Users/Logan/Code/rumor_analytics/csv/baseline_jan6_e_wNames.csv\"\n",
      "rumor_path = \"/Users/Logan/Code/rumor_analytics/csv/boston_no_subjectives_e_wNames.csv\"\n",
      "rumor_vert_path = \"/Users/Logan/Code/rumor_analytics/csv/boston_no_subjectives_v.csv\"\n",
      "\n",
      "baseline_edges = gl.SFrame.read_csv(baseline_path, True)\n",
      "rumor_edges = gl.SFrame.read_csv(rumor_path, True)\n",
      "rumor_verts = gl.SFrame.read_csv(rumor_vert_path, True)\n",
      "#Let's see what we have imported.\n",
      "baseline_edges.head()\n",
      "rumor_edges.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Filtering the Baseline Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#To get the subgraph of the baseline data \n",
      "#which corresponds to our rumor data, we will filter the baseline edge-list\n",
      "#by both of the 'Word' columns of our rumor data.\n",
      "\n",
      "rumor_words = rumor_edges.select_column(\"Word 1\") #Get the first word column.\n",
      "rumor_words = rumor_words.append(rumor_edges.select_column(\"Word 2\")) #Glue the second word column to the end of the first.\n",
      "\n",
      "#All of the words in the rumor set.\n",
      "rumor_words = rumor_words.unique()\n",
      "\n",
      "#All of the words which appear in BOTH sets.\n",
      "filtered_baseline = baseline_edges.filter_by(rumor_words, \"Word 1\").filter_by(rumor_words, \"Word 2\")\n",
      "\n",
      "#All baseline words.\n",
      "baseline_words = filtered_baseline.select_column(\"Word 1\").append(filtered_baseline.select_column(\"Word 2\"))\n",
      "baseline_words = baseline_words.unique()\n",
      "\n",
      "#Words which appear ONLY IN THE RUMOR SET\n",
      "rumor_only1 = rumor_edges.filter_by(baseline_words,\"Word 1\", exclude=True)\n",
      "rumor_only2 = rumor_edges.filter_by(baseline_words,\"Word 2\", exclude=True)\n",
      "rumor_only = rumor_only1.append(rumor_only2)\n",
      "rumor_only.show()\n",
      "\n",
      "#Now we'll add the terms that only occur in the rumor set to the baseline with a count of 0.\n",
      "rumor_only.remove_column('Co-occurrence')\n",
      "rumor_only.add_column(gl.SArray.from_const('0', rumor_only.num_rows()),'Co-occurrence') #Add a column of zeros.\n",
      "print rumor_only\n",
      "print 'Filtered', rumor_only.filter_by(['sunil'],'Word 1')\n",
      "filtered_baseline = filtered_baseline.append(rumor_only)\n",
      "print 'Before', filtered_baseline.filter_by(['craft'],'Word 1')\n",
      "\n",
      "#Change the name of co-occurence so we can tell the rumor and baseline counts appart.\n",
      "filtered_baseline.rename({'Co-occurrence':'Baseline'})\n",
      "\n",
      "#Remove search terms and rt terms.\n",
      "rumor_edges = rumor_edges.filter_by([\"boston\", \"marathon\", \"bomb\", \"explos\", \"blast\", 'r', 'rt'],\"Word 1\", exclude=True)\n",
      "rumor_edges = rumor_edges.filter_by([\"boston\", \"marathon\", \"bomb\", \"explos\", \"blast\", 'r', 'rt'],\"Word 2\", exclude=True)\n",
      "\n",
      "\n",
      "#Debug check\n",
      "print 'After', filtered_baseline.filter_by(['craft'],'Word 1')\n",
      "\n",
      "#Now let's join the counts into one SFrame (We will join a row if the pair of words matches.)\n",
      "combined_order = filtered_baseline.join(rumor_edges, on={'Word 1':'Word 1', 'Word 2':'Word 2'}) #All in ordr matches match.\n",
      "combined_reverse = filtered_baseline.join(rumor_edges, on={'Word 1':'Word 2', 'Word 2':'Word 1'}) #All reverse matches.\n",
      "\n",
      "\n",
      "combined = combined_order.append(combined_reverse)\n",
      "\n",
      "combined.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Comparing the Networks"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#We will take the difference between the baseline and the rumor data for each co-occurence pair.\n",
      "edge_difference = combined.apply(lambda x: int(x['Co-occurrence']) - int(x['Baseline']))\n",
      "combined.add_column(edge_difference,'Difference')\n",
      "\n",
      "#Find the point where \n",
      "combined_diff = combined.select_column('Difference')\n",
      "combined_max = combined_diff.max()\n",
      "\n",
      "combined_mean = combined_diff.mean()\n",
      "combined_std = combined_diff.std()\n",
      "z_threshold = int(combined_mean + (2*combined_std)) #Z-Score of +2\n",
      "\n",
      "#Filter our combined edgeset so we are left with the outliers from the right-side of the distribution.\n",
      "interesting = combined.filter_by(range(z_threshold,combined_max),'Difference')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "combined.save('boston_diff_full.csv','csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Viewing In GraphLab"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "interesting_gl = interesting.topk('Difference', 110)\n",
      "\n",
      "#Get the word-names for our interesting rows.\n",
      "temp = interesting_gl.select_column('Word 1').append(interesting_gl.select_column('Word 2')).unique()\n",
      "verts = rumor_verts.filter_by(temp,'word')\n",
      "verts.rename({'word':'__id'})\n",
      "\n",
      "\n",
      "#Create an SGraph so we can visualize the data:\n",
      "differenceGraph = gl.SGraph(vertices=verts, edges=interesting_gl, vid_field='__id',src_field='Word 1', dst_field='Word 2')\n",
      "\n",
      "#Now lets take a look:\n",
      "differenceGraph.show(vlabel='__id', elabel='Co-occurrence', elabel_hover=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Finding Cliques"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Export the edgelist.\n",
      "#combined.rename({'Word 1':'Source','Word 2':'Target','Difference':'Weight'}).save('boston_diff_e.csv',format='csv')\n",
      "interesting.remove_columns(['Co-occurrence','Baseline'])\n",
      "interesting.save('boston_diff_filtered.csv',format='csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Import our graph to NetworkX\n",
      "g = None\n",
      "headers = None\n",
      "with open('boston_diff_filtered.csv','rb') as f:\n",
      "    headers = f.readline()\n",
      "    g = nx.read_weighted_edgelist(f, comments='#', delimiter=',', encoding='utf-8')\n",
      "    \n",
      "nx.info(g)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Running the Clique-Finding Algorithm"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#cliques = list(nx.find_cliques(g))\n",
      "#print cliques"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}